{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os \n",
    "import csv\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "from PIL import ImageFile\n",
    "from sklearn.cluster import KMeans\n",
    "import transformers\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "import sklearn\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "import re\n",
    "import random\n",
    "from spellchecker import SpellChecker\n",
    "import inflect\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import PngImagePlugin\n",
    "LARGE_ENOUGH_NUMBER = 100\n",
    "PngImagePlugin.MAX_TEXT_CHUNK = LARGE_ENOUGH_NUMBER * (1024**2)\n",
    "import PIL.Image\n",
    "Image.MAX_IMAGE_PIXELS = None\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "# cuda visibile devices 0, 1\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] =  \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/home/trkosire/Factorynet/kevin__data_exploration_taxonomy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/trkosire/Factorynet/hack_env/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/home/trkosire/Factorynet/hack_env/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "label_embeddings = model.encode(df['label'].tolist())  \n",
    "\n",
    "kmeans = KMeans(n_clusters=18, random_state=0).fit(label_embeddings) \n",
    "\n",
    "df['cluster'] = kmeans.labels_\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 90\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m     89\u001b[0m ros \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m---> 90\u001b[0m X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m \u001b[43mros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m X \u001b[38;5;241m=\u001b[39m X_resampled\n\u001b[1;32m     92\u001b[0m y \u001b[38;5;241m=\u001b[39m y_resampled\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/imblearn/over_sampling/_random_over_sampler.py:158\u001b[0m, in \u001b[0;36mRandomOverSampler._check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    157\u001b[0m     y, binarize_y \u001b[38;5;241m=\u001b[39m check_target_type(y, indicate_one_vs_all\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 158\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43m_check_X\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/imblearn/utils/_validation.py:645\u001b[0m, in \u001b[0;36m_check_X\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m    643\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(X):\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\n\u001b[0;32m--> 645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    647\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/sklearn/utils/validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/sklearn/utils/_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "Cell \u001b[0;32mIn[10], line 76\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Apply appropriate transform based on the class\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mminority_classes:\n\u001b[0;32m---> 76\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43maggressive_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     image \u001b[38;5;241m=\u001b[39m standard_transform(image)\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torchvision/transforms/transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[0;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torchvision/transforms/transforms.py:1280\u001b[0m, in \u001b[0;36mColorJitter.forward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m   1278\u001b[0m         img \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39madjust_saturation(img, saturation_factor)\n\u001b[1;32m   1279\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m fn_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m hue_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1280\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torchvision/transforms/functional.py:968\u001b[0m, in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    966\u001b[0m     _log_api_usage_once(adjust_hue)\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m--> 968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjust_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue_factor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39madjust_hue(img, hue_factor)\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/torchvision/transforms/_functional_pil.py:109\u001b[0m, in \u001b[0;36madjust_hue\u001b[0;34m(img, hue_factor)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_mode \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m--> 109\u001b[0m h, s, v \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHSV\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msplit()\n\u001b[1;32m    111\u001b[0m np_h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(h, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# This will over/underflow, as desired\u001b[39;00m\n",
      "File \u001b[0;32m~/Factorynet/hack_env/lib/python3.8/site-packages/PIL/Image.py:1146\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m   1143\u001b[0m     dither \u001b[38;5;241m=\u001b[39m Dither\u001b[38;5;241m.\u001b[39mFLOYDSTEINBERG\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1146\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdither\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m         \u001b[38;5;66;03m# normalize source image and try again\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def filter_existing_images(df, image_dir):\n",
    "    existing_files = []\n",
    "    for file_name in df['file_name']:\n",
    "        if os.path.exists(os.path.join(image_dir, str(file_name))):\n",
    "            existing_files.append(file_name)\n",
    "    \n",
    "    return df[df['file_name'].isin(existing_files)].reset_index(drop=True)\n",
    "\n",
    "image_dir = \"/home/trkosire/Factorynet/hackathon/all_images/\" \n",
    "df = filter_existing_images(df, image_dir)\n",
    "\n",
    "\n",
    "# set random seed \n",
    "torch.manual_seed(42)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # Hyperparameters\n",
    "momentum = 0.9\n",
    "learning_rates = [0.01] # best learning rate is 0.01\n",
    "learning_rate_decay = 0.0001\n",
    "weight_decay = 0.0002\n",
    "num_epochs = 15\n",
    "batch_sizes = [16] # best batch size is 128\n",
    "early_stopping_patience = 5 \n",
    "\n",
    "\n",
    "MINORITY_THRESHOLD = 1000\n",
    "# Standard augmentation for majority classes\n",
    "standard_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# More aggressive augmentation for minority classes\n",
    "aggressive_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=30),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2), shear=10),\n",
    "    transforms.RandomPerspective(distortion_scale=0.2, p=0.5),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "# create a dataset for each cluster\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, image_dir):\n",
    "        self.df = df\n",
    "        self.image_paths = [os.path.join(image_dir, str(file_name)) for file_name in df['file_name']]\n",
    "        self.labels = df['cluster'].values\n",
    "        \n",
    "        # Determine minority classes\n",
    "        class_counts = df['cluster'].value_counts()\n",
    "        self.minority_classes = class_counts[class_counts < MINORITY_THRESHOLD].index.tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Apply appropriate transform based on the class\n",
    "        if label in self.minority_classes:\n",
    "            image = aggressive_transform(image)\n",
    "        else:\n",
    "            image = standard_transform(image)\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "    \n",
    "dataset = CustomDataset(df, image_dir)\n",
    "\n",
    "X = dataset\n",
    "y = dataset.labels\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "X = X_resampled\n",
    "y = y_resampled\n",
    "\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=42)\n",
    "\n",
    "# save X_train, X_val, X_test, y_train, y_val, y_test to disk\n",
    "# torch.save(X_train, 'X_train.pt')\n",
    "# torch.save(X_val, 'X_val.pt')\n",
    "# torch.save(X_test, 'X_test.pt')\n",
    "# torch.save(y_train, 'y_train.pt')\n",
    "# torch.save(y_val, 'y_val.pt')\n",
    "# torch.save(y_test, 'y_test.pt')\n",
    "\n",
    "# Load the data\n",
    "# X_train = torch.load('X_train.pt')\n",
    "# X_val = torch.load('X_val.pt')\n",
    "# X_test = torch.load('X_test.pt')\n",
    "# y_train = torch.load('y_train.pt')\n",
    "# y_val = torch.load('y_val.pt')\n",
    "# y_test = torch.load('y_test.pt')\n",
    "\n",
    "\n",
    "train_data = ConcatDataset([X_train])\n",
    "val_data = ConcatDataset([X_val])\n",
    "test_data = ConcatDataset([X_test])\n",
    "\n",
    "\n",
    "# print the distribution of the classes in the train, val and test set\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# Assuming y_train, y_val, and y_test are your label arrays for each set\n",
    "\n",
    "# Count occurrences of each class\n",
    "train_distribution = Counter(y_train)\n",
    "val_distribution = Counter(y_val)\n",
    "test_distribution = Counter(y_test)\n",
    "\n",
    "# Print distributions\n",
    "print(\"Train set class distribution:\")\n",
    "for class_label, count in sorted(train_distribution.items()):\n",
    "    print(f\"Class {class_label}: {count}\")\n",
    "\n",
    "print(\"\\nValidation set class distribution:\")\n",
    "for class_label, count in sorted(val_distribution.items()):\n",
    "    print(f\"Class {class_label}: {count}\")\n",
    "\n",
    "print(\"\\nTest set class distribution:\")\n",
    "for class_label, count in sorted(test_distribution.items()):\n",
    "    print(f\"Class {class_label}: {count}\")\n",
    "\n",
    "# Calculate percentages\n",
    "total_train = sum(train_distribution.values())\n",
    "total_val = sum(val_distribution.values())\n",
    "total_test = sum(test_distribution.values())\n",
    "\n",
    "print(\"\\nPercentage distribution:\")\n",
    "print(\"Class\\tTrain\\tVal\\tTest\")\n",
    "for class_label in sorted(set(train_distribution.keys()) | set(val_distribution.keys()) | set(test_distribution.keys())):\n",
    "    train_percent = train_distribution[class_label] / total_train * 100\n",
    "    val_percent = val_distribution[class_label] / total_val * 100\n",
    "    test_percent = test_distribution[class_label] / total_test * 100\n",
    "    print(f\"{class_label}\\t{train_percent:.2f}%\\t{val_percent:.2f}%\\t{test_percent:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model setup\n",
    "dropout_rate = 0.5\n",
    "\n",
    "class ModifiedResNet152(torch.nn.Module):\n",
    "    def __init__(self, original_model, dropout_rate):\n",
    "        super(ModifiedResNet152, self).__init__()\n",
    "        self.features = torch.nn.Sequential(*list(original_model.children())[:-1])\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.fc = torch.nn.Linear(original_model.fc.in_features, 11)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "from torchvision.models import ResNet152_Weights\n",
    "original_model = torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
    "model = ModifiedResNet152(original_model, dropout_rate)\n",
    "model = torch.nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# due to class imbalance we will use weighted cross entropy loss\n",
    "class_counts = df['cluster'].value_counts()\n",
    "class_weights = np.zeros(len(class_counts))\n",
    "for class_index, count in class_counts.items():\n",
    "    class_weights[class_index] = 1.0 / count\n",
    "class_weights = class_weights / class_weights.sum()\n",
    "class_weights = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "class FocalLoss(torch.nn.Module):\n",
    "    def __init__(self, gamma=2, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha, (float, int)): \n",
    "            self.alpha = torch.Tensor([alpha, 1 - alpha])\n",
    "        if isinstance(alpha, list): \n",
    "            self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim() > 2:\n",
    "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1, 2)    # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1, input.size(2))   # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1, 1)\n",
    "\n",
    "        logpt = F.log_softmax(input, dim=1)\n",
    "        logpt = logpt.gather(1, target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = logpt.exp()\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type() != input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0, target.data.view(-1))\n",
    "            logpt = logpt * at\n",
    "\n",
    "        loss = -1 * (1 - pt)**self.gamma * logpt\n",
    "        if self.size_average: \n",
    "            return loss.mean()\n",
    "        else: \n",
    "            return loss.sum()\n",
    "        \n",
    "        \n",
    "# Loss function and optimizer\n",
    "num_classes = df['cluster'].nunique()  \n",
    "alpha = torch.ones(num_classes, device=device)\n",
    "alpha = alpha * (1 - class_weights)  \n",
    "criterion = FocalLoss(gamma=2, alpha=alpha)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rates[0], momentum=momentum, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=learning_rate_decay)\n",
    "\n",
    "\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0, device=device):\n",
    "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    '''Compute the mixup loss'''\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "\n",
    "\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, test_loader, optimizer, scheduler, num_epochs, early_stopping_patience):\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    best_model_state = None\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for images, labels in train_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            images, targets_a, targets_b, lam = mixup_data(images, labels, alpha=1.0, device=device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Evaluate on validation set\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        # Evaluate on test set\n",
    "        test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                labels = labels.type(torch.LongTensor)\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Test Loss: {avg_test_loss:.4f}')\n",
    "\n",
    "        # Early stopping check\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            best_model_state = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "\n",
    "    # Restore best model\n",
    "    model.load_state_dict(best_model_state)\n",
    "    return model, best_val_loss, train_losses, val_losses, test_losses\n",
    "\n",
    "# Hyperparameter tuning\n",
    "best_hyperparams = {'learning_rate': None, 'batch_size': None, 'val_loss': float('inf')}\n",
    "best_model_state = None\n",
    "best_losses = None\n",
    "\n",
    "results = []\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for bs in batch_sizes:\n",
    "        print(f\"Training with learning rate: {lr}, batch size: {bs}\")\n",
    "\n",
    "        # Create dataloaders\n",
    "        train_loader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "        val_loader = DataLoader(val_data, batch_size=bs, shuffle=False)\n",
    "        test_loader = DataLoader(test_data, batch_size=bs, shuffle=False)\n",
    "\n",
    "        # Initialize model\n",
    "        model = ModifiedResNet152(torchvision.models.resnet18(weights=ResNet18_Weights.DEFAULT), dropout_rate=0.5)\n",
    "        model = model.to(device)\n",
    "\n",
    "        # Initialize optimizer and scheduler\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "        # Train and evaluate\n",
    "        model, val_loss, train_losses, val_losses, test_losses = train_and_evaluate(\n",
    "            model, train_loader, val_loader, test_loader, optimizer, scheduler, num_epochs, early_stopping_patience\n",
    "        )\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'lr': lr,\n",
    "            'bs': bs,\n",
    "            'train_losses': train_losses,\n",
    "            'val_losses': val_losses,\n",
    "            'test_losses': test_losses\n",
    "        })\n",
    "\n",
    "        # Update best hyperparameters if current combination is better\n",
    "        if val_loss < best_hyperparams['val_loss']:\n",
    "            best_hyperparams['learning_rate'] = lr\n",
    "            best_hyperparams['batch_size'] = bs\n",
    "            best_hyperparams['val_loss'] = val_loss\n",
    "            best_model_state = model.state_dict()\n",
    "            best_losses = (train_losses, val_losses, test_losses)\n",
    "\n",
    "print(f\"Best Hyperparameters: Learning Rate = {best_hyperparams['learning_rate']}, Batch Size = {best_hyperparams['batch_size']}\")\n",
    "\n",
    "# # Save the best overall model\n",
    "# torch.save(best_model_state, '18_best_model.pth')\n",
    "\n",
    "# # Save the losses for the best model\n",
    "# np.save('best_model_losses.npy', best_losses)\n",
    "\n",
    "# # Save all results\n",
    "# np.save('all_results.npy', results)\n",
    "\n",
    "# Plot learning curves for the best model\n",
    "train_losses, val_losses, test_losses = best_losses\n",
    "\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(train_losses, label='Training Loss', color = 'red')\n",
    "# plt.plot(val_losses, label='Validation Loss', color = 'blue')\n",
    "# plt.plot(test_losses, label='Test Loss', color = 'green')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title(f'Learning Curves (LR={best_hyperparams[\"learning_rate\"]}, BS={best_hyperparams[\"batch_size\"]})')\n",
    "# plt.legend()\n",
    "# plt.savefig('learning_curves.png')\n",
    "# plt.close()\n",
    "\n",
    "# # Create plots for each hyperparameter combination\n",
    "# for result in results:\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.plot(result['train_losses'], label='Training Loss', color = 'red')\n",
    "#     plt.plot(result['val_losses'], label='Validation Loss', color = 'blue')\n",
    "#     plt.plot(result['test_losses'], label='Test Loss', color = 'green')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title(f'Learning Curves (LR={result[\"lr\"]}, BS={result[\"bs\"]})')\n",
    "#     plt.legend()\n",
    "#     plt.savefig(f'learning_curves_lr{result[\"lr\"]}_bs{result[\"bs\"]}.png')\n",
    "#     plt.close()\n",
    "\n",
    "\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            labels = labels.type(torch.LongTensor)\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    return np.array(all_predictions), np.array(all_labels)\n",
    "\n",
    "# Load the best model\n",
    "# best_model = ModifiedResNet152(torchvision.models.resnet152(weights=ResNet152_Weights.DEFAULT), dropout_rate=0.5)\n",
    "# best_model = best_model.to(device)\n",
    "# best_model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Create test DataLoader\n",
    "# test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "# Get predictions\n",
    "predictions, true_labels = evaluate_model(model, test_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Calculate per-class metrics\n",
    "class_precision, class_recall, class_f1, _ = precision_recall_fscore_support(true_labels, predictions, average=None)\n",
    "\n",
    "# Print per-class metrics\n",
    "for i in range(len(class_precision)):\n",
    "    print(f\"Class {i}:\")\n",
    "    print(f\"  Precision: {class_precision[i]:.4f}\")\n",
    "    print(f\"  Recall: {class_recall[i]:.4f}\")\n",
    "    print(f\"  F1 Score: {class_f1[i]:.4f}\")\n",
    "\n",
    "\n",
    "# Create a confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cm = confusion_matrix(true_labels, predictions)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "# plt.savefig('confusion_matrix.png')\n",
    "# plt.close()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hack_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
